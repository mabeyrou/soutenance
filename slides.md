---
theme: seriph
background: assets/pictures/premium_photo-1663039978729-6f6775725f89.avif
title: Pr√©diction des retards d'avion
info: |
  ## Soutenance "Concevoir et Impl√©menter une Solution IA"
  Marion Roussel
class: text-center
transition: fade-out
drawings:
  persist: false
mdc: true
seoMeta:
  ogImage: "auto"
hideInToc: true
---
# Pr√©diction des retards d'avion
### Soutenance "Concevoir et Impl√©menter une Solution IA"
#### Marion Roussel

---
transition: slide-left
layout: quote
hideInToc: true
---
# Marion Roussel
- ü©∫ - **Infirmi√®re** de formation  
  
- üåê - **Reconvertion** dans le d√©veloppement web

- üë©üèº‚Äçüíª - **D√©veloppeuse full-stack** interm√©diaire

- üìä - Int√©r√™t pour la **donn√©e** et l'**IA**

<!--
Marion Roussel
Infirmi√®re de formation, reconvertie autodidacte dans le d√©veloppement web depuis 3 ans et demi.
J'occupe actuellement un poste de d√©veloppeuse full-stack interm√©diaire, au sein de l'√©quipe Produit d'une entreprise de e-sant√©.
Mon parcours m'a oblig√© √† prendre des raccourcis et m'a rendu moins g√©n√©raliste que d'autre profil. Mais je m'efforce de combler ces angles morts par de la formation continue.
Dans ce contexte, la donn√©e et l'IA ont toujours attis√©es ma curiosit√© mais me semblaient innaccessibles, voil√† ce qui m'a amen√© √† suivre cette formation.
-->

---
transition: slide-left
layout: intro
hideInToc: true
---
# Soutenance
Dans le cadre de cette formation, nous avons d√ª travailler sur un jeu de donn√©es concernant les **retards d'avion** aux √âtats-Unis.  
Nous devions l'**analyser**, le **traiter**, l'utiliser pour cr√©er un **mod√®le de pr√©diction des retards** et int√©grer tout cela dans une **application** maintenable et robuste.

---
layout: image-right
image: "assets/pictures/photo-1504150558240-0b4fd8946624.avif"
hideInToc: true
---

# Table des mati√®res
<Toc minDepth="1" maxDepth="2" class="text-sm"/>

---
level: 1
transition: slide-left
layout: image-left
image: "assets/pictures/premium_photo-1677281438593-0daee23b3bc7.avif"
---
# Le contexte
- üõ´ ~ 19% de vols retard√©s en 2019 aux √âtats-Unis
  
- üí∏ 28 milliards de dollars de perte

- üö® enjeu majeur pour les compagnies a√©riennes

- üîÄ multifactoriel et complexe  
<br/>
<br/>
=> ü§ñ cr√©ation d'un mod√®le de pr√©diction
<!--
Selon le Bureau of Transportation Statistics des √âtats-Unis, environ 19 % des vols ont √©t√© retard√©s en
2019, engendrant des co√ªts √©conomiques estim√©s √† 28 milliards de dollars.
Les retards d'avion repr√©sentent donc un enjeu majeur pour les compagnies a√©riennes.
Il s'agit cependant d'un ph√©nom√®ne multifactoriel et complexe, influenc√© tant par les conditions m√©t√©orologiques, la congestion du trafic a√©rien,
des probl√®mes techniques ou op√©rationnels.
Dans ce cadre, il nous a √©t√© demand√© de cr√©er un mod√®le de pr√©diction des retards √† partir de donn√©es historiques du Bureau of Transportation Statistics des √âtats-Unis.
-->

---
transition: slide-left
level: 1
layout: section
image: "assets/pictures/photo-1569154941061-e231b4725ef1.avif"
---
# Les donn√©es

<!--
-->

---
transition: slide-left
level: 2
layout: section
layout: image-right
image: "assets/pictures/premium_photo-1681586533774-1d9d42425712.avif"
---
<p class="text-xs text-blue-300">Les donn√©es ‚∏± Description</p>


# Description du jeu de donn√©es
<br/>

> Donn√©es issues du Bureau of Transportation Statistics des √âtats-Unis

<br/>

- 12 fichiers `.csv` de 147 √† 175Mo
  
- un fichier par mois de l'ann√©e 2016
- chaque fichier compte plus de 450 000 lignes
- total ~ 5,6 millions de lignes

<!--
-->

---
transition: slide-left
level: 2
layout: image-left
image: "assets/pictures/premium_photo-1661340638286-7ce343262c4c.avif"
---
<p class="text-xs text-blue-300">Les donn√©es ‚∏± Les difficult√©s</p>

# Les difficult√©s
- Taille du jeu de donn√©es 
  - probl√®mes r√©currents de RAM
  
  - librairies vues en formation, inadapt√©es au volume
- Jeu de donn√©es moins propre
  - plus de traitement
  
  - plus d'hypth√®ses √† tester

<!--
Pour traiter ce jeu de donn√©es, j'ai √©t√© confront√©e √† plusieurs difficult√©s. Je n'avais notamment jamais travaill√© avec un jeu de donn√©es d'une telle ampleur. Lorsque j'ai d√©couvert les donn√©es pour la premi√®re fois, j'avais anticip√© ces difficult√©s, mais elles ont √©t√© plus contraignantes qu'anticip√©. J'ai r√©guli√®rement √©t√© confront√©e √† des probl√®mes de RAM, avec, au choix, mon √©diteur ou mon PC qui s'√©teignait intempestivement. J'ai malheureusement d√©couvert, trop tard, la librairie de Polars.
Par ailleurs, le jeu de donn√©es √©tait moins propre que les jeux avec lesquels nous avons travaill√© durant la formation. Cela est sans doute plus repr√©sentatif des donn√©es du monde r√©el, mais cela m'a demand√© une analyse et un traitement plus approfondis que ce que j'avais pu faire durant la formation. Notamment concernant les donn√©es manqueantes pour lesquelles j'ai d√ª √©laborer des hypoth√®ses qu'il a fallu tester. 
-->  

---
transition: slide-left
level: 2
---
<p class="text-xs text-blue-300">Les donn√©es ‚∏± L'analyse</p>

# L'analyse

<!--
-->

---
transition: slide-left
layout: section
level: 1
---
# Le mod√®le
### Classification binaire

<!--
Dans notre contexte, il s'agit de pr√©dire si, en fonction de certaines informaitons, un vol sera ou non en retard. En terme de mod√®le, il s'agit d'un probl√®me de classification binaire. Pour ce faire, j'ai choisi de me concentrer sur 3 mod√®les diff√©rents afin de les comparer et de choisir le meilleur des 3.
-->

---
transition: slide-left
layout: two-cols-header
level: 2
---
<p class="text-xs text-blue-300">Le mod√®le ‚∏± Les mod√®les en comp√©tition</p>

# Les mod√®les en comp√©tition

::left::
- Diversit√© des approches
- Compl√©mentarit√©
- Robustesse
- Standards de l'industrie

::right::
### üìà Logistic Regression
Mod√®le lin√©aire simple et interpr√©table.

### üå≥ Random Forest
M√©thode d'ensemble qui combine de multiples arbres de d√©cision entra√Æn√©s sur des √©chantillons diff√©rents du dataset.

### ü§ñ LightGBM
Algorithme de boosting gradient optimis√© pour la vitesse et l'efficacit√© m√©moire.

<!--
# Les mod√®les en comp√©tition
- Diversit√© des approches : Mod√®le lin√©aire (Logistic Regression), ensemble d'arbres (Random Forest), et boosting gradient (LightGBM)
- Compl√©mentarit√© : Du plus simple au plus complexe, du plus ancien au plus moderne, permettant d'√©valuer si la complexit√© apporte un gain de performance
- Robustesse : Couvrent diff√©rents types de relations dans les donn√©es (lin√©aires vs non-lin√©aires)
- R√©f√©rences : Standards de l'industrie avec des performances reconnues

## Logistic Regression
Mod√®le lin√©aire simple et interpr√©table qui estime la probabilit√© d'appartenance √† une classe via la fonction logistique. Rapide √† entra√Æner et efficace sur des relations lin√©aires, il sert souvent de baseline pour √©valuer des mod√®les plus complexes.

## Random Forest
M√©thode d'ensemble qui combine de multiples arbres de d√©cision entra√Æn√©s sur des √©chantillons diff√©rents du dataset. Robuste au surapprentissage et capable de capturer des relations non-lin√©aires complexes, il offre √©galement une bonne interpr√©tabilit√© via l'importance des features.

## LightGBM
Algorithme de boosting gradient optimis√© pour la vitesse et l'efficacit√© m√©moire, utilisant une approche leaf-wise pour construire les arbres. Particuli√®rement performant sur de gros datasets, il excelle dans la capture de patterns complexes tout en √©tant moins susceptible au surapprentissage que d'autres m√©thodes de
-->

---
transition: slide-left
layout: image-right
image: "assets/pictures/photo-1670926774123-4e36ed8f5fd1.avif"
level: 2
---
<p class="text-xs text-blue-300">Le mod√®le ‚∏± La pr√©paration des donn√©es</p>

# Pr√©paration des donn√©es
- split des donn√©es
- traitement des valeurs num√©riques :
  - imputation -> **SimpleImputer**
  - normalisation et standardisation -> **StandardScaler**
- traitement des valeurs cat√©gorielles
  - imputation -> **SimpleImputer**
  - encodage -> **OneHotEncoder**


---
transition: slide-left
level: 2
---
<p class="text-xs text-blue-300">Le mod√®le ‚∏± La cross-validation</p>

# La cross-validation
- Int√©gration de la pipeline compl√®te (pr√©traitement + mod√®le)
- GridSearchCV

<!--
-->

---
transition: fade
layout: image-left
image: "assets/pictures/photo-1664854953181-b12e6dda8b7c.avif"
level: 3
---
<p class="text-xs text-blue-300">Le mod√®le ‚∏± La cross-validation ‚∏± Logistic Regression</p>

# Logistic Regression

```python
param_grid = {
    "C": [0.01, 0.1, 1, 10, 100],
    "penalty": ["l1", "l2"],
    "solver": ["liblinear", "saga"],
    "class_weight": ["balanced", None],
}
```
<p class="text-sm">

- Param√®tre C (R√©gularisation) : 1

- Penalty (Type de r√©gularisation) : l2

- Solver (Algorithme d'optimisation) : saga

- Class_weight (Gestion du d√©s√©quilibre) : None

Meilleur score CV Logistic Regression : 0.9118
</p>



<!--
Param√®tre C (R√©gularisation)
C contr√¥le l'inverse de la force de r√©gularisation
-Valeurs faibles (0.01, 0.1) = forte r√©gularisation ‚Üí pr√©vient le surapprentissage
-Valeurs √©lev√©es (10, 100) = faible r√©gularisation ‚Üí mod√®le plus complexe
-Progression logarithmique couvre efficacement l'espace des param√®tres

Penalty (Type de r√©gularisation)
- L1 (Lasso) : s√©lection automatique de features, peut mettre des coefficients √† z√©ro
- L2 (Ridge) : r√©duction uniforme des coefficients, garde toutes les features
- Teste deux approches compl√©mentaires de r√©gularisation

Solver (Algorithme d'optimisation)
- liblinear : efficace pour petits datasets, supporte L1 et L2
- saga : adapt√© aux gros datasets, convergence rapide, supporte L1 et L2
- Compatibilit√© avec les diff√©rents types de p√©nalit√©s

Class_weight (Gestion du d√©s√©quilibre)
- "balanced" : ajuste automatiquement les poids selon la fr√©quence des classes
- None : poids √©gaux pour toutes les classes
- Important pour les datasets d√©s√©quilibr√©s (comme les retards d'avion)
-->

---
transition: fade
layout: image-left
image: "assets/pictures/photo-1664854953181-b12e6dda8b7c.avif"
level: 3
---
<p class="text-xs text-blue-300">Le mod√®le ‚∏± La cross-validation ‚∏± Random Forest</p>

# Random Forest
```python
param_grid_rf = {
    "n_estimators": [100, 200, 300],
    "max_depth": [None, 10, 20, 30],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4],
    "class_weight": ["balanced", "balanced_subsample", None],
}
```
<p class="text-sm">

- N_estimators (Nombre d'arbres) : 200
- Max_depth (Profondeur maximale): 20
- min_samples_split (√âchantillons minimum) : 5
- Min_samples_leaf (√âchantillons minimum par feuille) : 1
- Class_weight (Gestion du d√©s√©quilibre): None
  
Meilleur score CV Random Forest : 0.9018
</p>

<!--
N_estimators (Nombre d'arbres)
- Plus d'arbres = meilleure performance mais temps d'entra√Ænement plus long
- 100 : baseline raisonnable pour tester rapidement
- 200-300 : exploration de l'am√©lioration avec plus d'arbres
Compromis performance/temps de calcul

Max_depth (Profondeur maximale)
- None : arbres d√©velopp√©s jusqu'aux feuilles pures (risque de surapprentissage)
- 10, 20, 30 : limitation de la profondeur pour contr√¥ler la complexit√©
- Param√®tre cl√© pour √©viter le surapprentissage sur des donn√©es complexes

Min_samples_split (√âchantillons minimum pour diviser)
2 : valeur par d√©faut, division aggressive
5, 10 : exige plus d'√©chantillons avant division ‚Üí arbres moins profonds
Contr√¥le la granularit√© des divisions et pr√©vient le surapprentissage

Min_samples_leaf (√âchantillons minimum par feuille)
- 1 : feuilles peuvent contenir un seul √©chantillon (par d√©faut)
- 2, 4 : force des feuilles plus "peupl√©es" ‚Üí g√©n√©ralisation am√©lior√©e
- Lisse les pr√©dictions et r√©duit la variance

Class_weight (Gestion du d√©s√©quilibre)
- "balanced" : ajuste les poids selon la distribution globale des classes
- "balanced_subsample" : ajuste les poids pour chaque arbre individuellement
- None : pas d'ajustement de poids
- Essentiel pour les datasets d√©s√©quilibr√©s comme les retards d'avion

Cette grille explore efficacement le compromis biais-variance et la robustesse aux donn√©es d√©s√©quilibr√©es.
-->

---
transition: fade
layout: image-left
image: "assets/pictures/photo-1664854953181-b12e6dda8b7c.avif"
level: 3
---
<p class="text-xs text-blue-300">Le mod√®le ‚∏± La cross-validation ‚∏± LightGBM</p>

# LightGBM

```python
param_grid_lgbm = {
    "n_estimators": [100, 200, 300],
    "learning_rate": [0.01, 0.1, 0.2],
    "num_leaves": [31, 50, 70],
    "objective": ["binary"],
    "metric": ["binary_logloss"],
}
```

<p class="text-sm">

- N_estimators (Nombre d'estimateurs) : 300
- Learning_rate (Taux d'apprentissage) : 0.1
- Num_leaves (Nombre de feuilles) : 31
- Objective : `binary`
- Metric : `binary_logloss`

Meilleur score CV LightGBM : 0.9110
</p>

<!--
Ce choix d'hyperparam√®tres pour LightGBM est pertinent car il explore les aspects cl√©s du boosting gradient :

N_estimators (Nombre d'estimateurs)
- Plus d'estimateurs = mod√®le plus complexe mais risque de surapprentissage
- 100 : baseline rapide pour tester
- 200-300 : exploration de l'am√©lioration avec plus d'it√©rations
- √âquilibre entre performance et temps d'entra√Ænement

Learning_rate (Taux d'apprentissage)
- 0.01 : apprentissage lent mais stable, n√©cessite plus d'estimateurs
- 0.1 : valeur par d√©faut, bon compromis vitesse/stabilit√©
- 0.2 : apprentissage rapide mais risque d'instabilit√©
- Contr√¥le la contribution de chaque arbre au mod√®le final

Num_leaves (Nombre de feuilles)
- 31 : valeur par d√©faut, mod√®le simple
- 50-70 : complexit√© accrue pour capturer des patterns plus fins
- Param√®tre cl√© de LightGBM (approche leaf-wise vs level-wise)
- Plus de feuilles = mod√®le plus expressif mais risque de surapprentissage

Objective et Metric
- Objective "binary" : sp√©cifie la t√¢che de classification binaire
- Metric "binary_logloss" : optimise la log-vraisemblance pour la classification
- Configuration appropri√©e pour le probl√®me de pr√©diction des retards

Cette grille explore efficacement le compromis biais-variance sp√©cifique au boosting gradient.
-->

---
transition: slide-left
layout: two-cols-header
level: 2
---
<p class="text-xs text-blue-300">Le mod√®le ‚∏± Les m√©triques analys√©es</p>

# Les m√©triques analys√©es

::left::
**Precision (Pr√©cision)**   
La proportion de pr√©dictions positives faites par le mod√®le qui sont effectivement correctes.  

`Precision = VP / (VP + FP)`

<br/>
<br/>

**Recall (Rappel ou Sensibilit√©)**  
La proportion de cas positifs r√©els que le mod√®le a correctement identifi√©s.

`Recall = VP / (VP + FN)`

::right::
**F1-Score**  
La moyenne harmonique de la precision et du recall.

`F1-score = 2 √ó (Precision √ó Recall) / (Precision + Recall)`

<br/>
<br/>

**AUC ROC**  
La capacit√© du mod√®le √† distinguer entre les classes sur l'ensemble des seuils de classification possibles.

<!--
Voici les d√©finitions de ces m√©triques essentielles pour √©valuer les mod√®les de classification binaire :

## Precision (Pr√©cision)
La precision mesure la proportion de pr√©dictions positives qui sont effectivement correctes. Elle r√©pond √† la question : "Parmi tous les cas que le mod√®le a class√©s comme positifs, combien le sont r√©ellement ?"

**Formule :** Precision = VP / (VP + FP)
o√π VP = Vrais Positifs, FP = Faux Positifs

## Recall (Rappel ou Sensibilit√©)
Le recall mesure la proportion de cas positifs r√©els que le mod√®le a correctement identifi√©s. Il r√©pond √† la question : "Parmi tous les cas r√©ellement positifs, combien le mod√®le en a-t-il d√©tect√©s ?"

**Formule :** Recall = VP / (VP + FN)
o√π FN = Faux N√©gatifs

## F1-Score
Le F1-score est la moyenne harmonique de la precision et du recall. Il fournit une mesure √©quilibr√©e qui p√©nalise les mod√®les ayant une grande diff√©rence entre precision et recall.

**Formule :** F1-score = 2 √ó (Precision √ó Recall) / (Precision + Recall)

La moyenne harmonique
C'est l'inverse de la moyenne arithm√©tique des inverses des termes. La moyenne harmonique est donc utilis√©e lorsqu'on veut d√©terminer un rapport moyen, dans un domaine o√π il existe des liens de proportionnalit√© inverses. 

## Support
Le support indique le nombre d'occurrences r√©elles de chaque classe dans l'√©chantillon de test. Ce n'est pas une m√©trique de performance √† proprement parler, mais plut√¥t une information contextuelle sur la distribution des donn√©es.

## AUC ROC (Area Under the Curve - Receiver Operating Characteristic)
L'AUC ROC mesure la capacit√© du mod√®le √† distinguer entre les classes sur l'ensemble des seuils de classification possibles. La courbe ROC trace le taux de vrais positifs contre le taux de faux positifs.

**Interpr√©tation :** Une AUC de 0,5 indique une performance al√©atoire, tandis qu'une AUC de 1,0 repr√©sente une classification parfaite. Plus l'AUC est proche de 1, meilleure est la performance du mod√®le.

Ces m√©triques sont compl√©mentaires et permettent d'√©valuer diff√©rents aspects de la performance d'un mod√®le selon le contexte applicatif et l'importance relative des erreurs de type I et II.
-->


---
transition: slide-left
layout: two-cols-header
level: 3
---
<p class="text-xs text-blue-300">Le mod√®le ‚∏± Les m√©triques analys√©es ‚∏± Logistic Regression</p>

# Logistic Regression
::left::
```
------------------------------------------------------------
√âvaluation du meilleur mod√®le de r√©gression logistique
------------------------------------------------------------
Pr√©cision r√©gression logistique : 0.9162

Rapport de classification :
              precision    recall  f1-score   support

         0.0       0.90      0.93      0.92     10078
         1.0       0.93      0.90      0.91      9922

    accuracy                           0.92     20000
   macro avg       0.92      0.92      0.92     20000
weighted avg       0.92      0.92      0.92     20000
```

::right::
<div class="flex justify-end h-full">
<img src="./assets/pictures/confusion_matrix_LogisticRegression.png" class="h-3/4"/>
</div>
<!--
-->

---
transition: slide-left
layout: two-cols-header
level: 3
---
<p class="text-xs text-blue-300">Le mod√®le ‚∏± Les m√©triques analys√©es ‚∏± Random Forest</p>

# Random Forest
::left::

```
------------------------------------------------------------
√âvaluation du meilleur mod√®le Random Forest
------------------------------------------------------------
Pr√©cision Random Forest : 0.9055

Rapport de classification Random Forest :
              precision    recall  f1-score   support

         0.0       0.89      0.93      0.91     10078
         1.0       0.92      0.88      0.90      9922

    accuracy                           0.91     20000
   macro avg       0.91      0.91      0.91     20000
weighted avg       0.91      0.91      0.91     20000
```

::right::

<div class="flex justify-end h-full">
<img src="./assets/pictures/confusion_matrix_RandomForest.png" class="h-3/4"/>
</div>

<!--
-->

---
transition: slide-left
layout: two-cols-header
level: 3
---

<p class="text-xs text-blue-300">Le mod√®le ‚∏± Les m√©triques analys√©es ‚∏± LightGBM</p>

# LightGBM

::left::
```
------------------------------------------------------------
√âvaluation du meilleur mod√®le LightGBM
------------------------------------------------------------
Pr√©cision LightGBM : 0.9139

Rapport de classification LightGBM :
              precision    recall  f1-score   support

         0.0       0.90      0.94      0.92     10078
         1.0       0.93      0.89      0.91      9922

    accuracy                           0.91     20000
   macro avg       0.91      0.91      0.91     20000
weighted avg       0.91      0.91      0.91     20000
```

::right::
<div class="flex justify-end h-full">
<img src="./assets/pictures/confusion_matrix_LightGBM.png" class="h-3/4"/>
</div>

<!--
-->


---
transition: slide-left
level: 3
---
<p class="text-xs text-blue-300">Le mod√®le ‚∏± Les m√©triques analys√©es ‚∏± Comparaison</p>

# Comparaison

|Mod√®le|Accuracy|Precision|Recall|F1-score|AUC-ROC|
|------|--------|---------|------|--------|-------|
|Logistic Reg|0.9162|  0.9304|  0.8982|  0.9140|  0.9670| 
|LightGBM|  0.9139|  0.9318|  0.8918|  0.9113|  0.9700| 
|Random Forest|0.9055|  0.9244|  0.8816|  0.9025|  0.9545| 
<!--
Etonnantes performances de la LR, qui s'expliquent peut-√™tre par 
-->

---
transition: slide-left
layout: statement
level: 2
---
<p class="text-xs text-blue-300">Le mod√®le ‚∏± Le choix du mod√®le</p>

# Le choix du mod√®le

<br/>

## LightGBM

<!--
Les 3 mod√®les ont obtenus de tr√®s bonnes performance
-->

---
transition: slide-left
layout: section
level: 1
---
# L'application


<!--
-->

---
transition: slide-left
level: 2
---
<p class="text-xs text-blue-300">L'application ‚∏± La d√©mo</p>

# La d√©mo


<!--
-->

---
transition: slide-left
level: 2
---
<p class="text-xs text-blue-300">L'application ‚∏± Architecture</p>

# Architecture


<!--
-->

---
transition: slide-left
layout: image-left
image: "assets/pictures/photo-1654277041218-84424c78f0ae.avif"
level: 2
---
<p class="text-xs text-blue-300">L'application ‚∏± Github</p>

# Github
- versionning avec Git
- h√©bergement avec Github
- Github actions pour la CI/CD

<!--
-->

---
transition: slide-left
level: 2
---
<p class="text-xs text-blue-300">L'application ‚∏± Monitoring</p>

# Monitoring


<!--
-->

---
transition: slide-left
level: 2
---
<p class="text-xs text-blue-300">L'application ‚∏± Les am√©liorations √† pr√©voir</p>

# Les am√©liorations √† pr√©voir
- syst√®me de r√©entrainement
- gestion des donn√©es ayant d√©j√† servi √† l'entra√Ænement ou non
- utiliation d'optima pour le choix des hyperparam√®tres


